# import needed packages 
import openai
import os 
from datetime import datetime

# Set up OpenAI API key.
api_key = 'API_Key'
openai.api_key = api_key

#--------------------------------- Task 1:  interpret contractual clauses.---------------------------------------

def interpret_contract_clause(clause_text, openai_engine='gpt-3.5-turbo'):
    """
    Analyzes and Interprets a contract clause for potential pitfalls, non-standard terms, or unfavorable conditions.

    Args:
        clause_text (str): The text of the contract clause to be analyzed.
        openai_engine (str): The OpenAI engine to use for analysis. Options are 'gpt-3.5-turbo', 'text-davinci-003', or 'text-davinci-002'.

    Returns:
        str: The analysis of the contract clause.

    Raises:
        ValueError: If an unsupported OpenAI engine is provided.
    """

    # Define the prompt
    prompt = f"Please interpret the following contract clause and identify any potential pitfalls, non-standard terms, or unfavorable conditions:\n\n{clause_text}\n\nInterpretation:\n\nAnalysis:"

    if openai_engine == 'gpt-3.5-turbo':
        # Create a chat conversation for gpt-3.5-turbo
        conversation = [
            {"role": "system", "content": "You are a contract analysis assistant."},
            {"role": "user", "content": prompt},
        ]

        # Generate analysis using gpt-3.5-turbo
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=conversation,
        )

        # Extract and return the analysis
        analysis = response['choices'][0]['message']['content'].strip()
        return analysis

    elif openai_engine in ['text-davinci-003', 'text-davinci-002']:
        # Generate analysis using text-davinci-003 or text-davinci-002
        response = openai.Completion.create(
            engine=openai_engine,
            prompt=prompt,
            max_tokens=150,     # Limit the length of the response
            n=1,                # Generate a single completion
            stop=None,          # Allow the model to complete the entire analysis
            temperature=0.7,    # Control the randomness of the output
        )

        # Extract and return the analysis
        analysis = response.choices[0].text.strip()
        return analysis

    else:
        # Raise an error for unsupported engine names
        raise ValueError("Unsupported OpenAI engine. Please use 'gpt-3.5-turbo', 'text-davinci-003', or 'text-davinci-002'.")





#-------------------------------------- Task 2: Clause Suggestion & Drafting.---------------------------------------


def suggest_contract_clauses(contract_data_str):

    """
    Generate suggestions for contract clauses or modifications based on provided contract data and negotiation history.

    Args:
    contract_data_str (str): A JSON string representing the contract data and negotiation history.

    Returns:
    str: Suggested contract clauses and modifications generated by the AI.

    Raises:
    openai.error.OpenAIError: Raised in case of OpenAI API errors, such as connection issues or rate limits.
    
    """
    # define the prompt 
    prompt = f"Based on the company's standard terms and previous negotiation data, you should suggest clauses or modifications to ensure company interests are protected while still being fair to the counterpart. Here is the current contract data and negotiation history:\n\n{contract_data_str}\n\nSuggested clauses and modifications:"


    # Define a clear and informative conversation for chat-based API
    conversation = [
        {"role": "system", "content": "You are an AI contract expert."},
        {"role": "user", "content": prompt},
    ]

    try:
        # Make an API call to GPT-3.5 Turbo with the conversation
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=conversation,
            max_tokens=200,      # Limit the length of the response
            n=5,                 # Generate multiple suggestions for flexibility
            stop=None,           # Allow the model to complete the entire analysis
            temperature=0.7,     # Control the randomness of the output
        )


        # Evaluate, customize, and incorporate suggestions into your contract draft

        suggesitons = response.choices[0].text.strip()
        return suggesitons

    except openai.error.OpenAIError as e:
        # Handle OpenAI API errors, e.g., connection issues, rate limits, etc.
        raise e



#-------------------------------------- Task 3: Real-time Negotiation Assistance.---------------------------------------

def real_time_negotiation_assistance(user_message):
    """
    Provides real-time negotiation assistance using the OpenAI GPT-3.5 Turbo model.

    The function allows users to engage in a simulated negotiation with the AI model.
    Users can type messages, and the AI model responds with insights and suggestions.

    Args:
        user_message (str): The message from the user.

    Returns:
        str: The AI's response message.
    """
    try:
        # Send user's message to the AI model
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are an expert negotiator you should provide real-time insights, suggest counterpoints, highlight standard industry terms, or indicate potential areas of compromise."},
                {"role": "user", "content": user_message},
            ]
        )

        ai_message = response['choices'][0]['message']['content']
        return str(ai_message)

    except openai.error.OpenAIError as e:
        # Handle OpenAI API errors
        return f"AI: An error occurred with the OpenAI API: {e}"

#-------------------------------------- Task 4: Historical Data Analysis. ---------------------------------------

def analyze_past_negotiations(negotiation_data):
    """
    Equip the AI to analyze past negotiations, learning from successful compromises, stalemates,
    and points of contention to refine future negotiation strategies.

    Args:
        negotiation_data (str): Textual data containing information about past negotiations.

    Returns:
        str: Insights and recommendations for future negotiation strategies based on historical data.
    """
    # Define a prompt that combines the provided statement and historical negotiation data
    prompt = f"Analyze past negotiations, learning from successful compromises, stalemates, and points of contention to refine future negotiation strategies.\n\nHistorical Data:\n{negotiation_data}\n\nInsights:"

    try:
        # Make an API call to GPT-3.5 Turbo with the prompt
        response = openai.Completion.create(
            engine="text-davinci-003",
            prompt=prompt,
            max_tokens=150,   # Adjust max tokens as needed
            n=1,              # Generate a single response
            stop=None,        # Allow the model to complete the entire analysis
            temperature=0.7,  # Control the randomness of the output
        )

        insights = response.choices[0].text.strip()
        return insights

    except openai.error.OpenAIError as e:
        # Handle OpenAI API errors
        return f"An error occurred with the OpenAI API: {e}"


#-------------------------------------- Task 5: Stakeholder Communication. ---------------------------------------

def generate_negotiation_summary(negotiation_details):
    """
    Generate a concise summary post-negotiation.

    Args:
        negotiation_details (str): Textual details of the negotiation, including terms, concerns, and next steps.

    Returns:
        str: Concise summary of the negotiation, highlighting terms agreed upon, potential areas of concern, and next steps.
    """
    # Define a prompt for generating the negotiation summary
    prompt = f"Generate concise summaries post-negotiation, detailing the terms agreed upon, potential areas of concern, and next steps of the negotiation:\n\n{negotiation_details}\n\nSummary:"

    try:
        # Make an API call to GPT-3.5 Turbo with the prompt
        response = openai.Completion.create(
            engine="text-davinci-003",
            prompt=prompt,
            max_tokens=150,   # Adjust max tokens as needed
            n=1,              # Generate a single response
            stop=None,        # Allow the model to complete the entire summary
            temperature=0.7,  # Control the randomness of the output
        )

        summary = response.choices[0].text.strip()
        return summary

    except openai.error.OpenAIError as e:
        # Handle OpenAI API errors
        return f"An error occurred with the OpenAI API: {e}"



#-------------------------------------- Task 6: Ethical & Compliance Check. ---------------------------------------

def ensure_compliance_and_ethical_standards(negotiation_data_str, industry):
    """
    Incorporate a module to ensure compliance with industry regulations and ethical standards.

    Args:
        negotiation_text (str): The negotiation text to be analyzed.
        industry (str): The industry or sector for which compliance is required.

    Returns:
        str: Guidance on ensuring compliance and ethical standards.
    """
    # Define a dynamic prompt with the industry included
    prompt = f"Based on the provided negotiation data in the {industry} industry:\n\n{negotiation_data_str}\n\nPlease provide insights and recommendations related to compliance and ethical considerations within this industry."

    try:
        # Make an API call to GPT-3.5 Turbo with the prompt
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"You are an AI expert in negotiations."},
                {"role": "user", "content": prompt},
            ]
        )

        # Extract and print the AI's response
        ai_response = response['choices'][0]['message']['content']
        return ai_response

    except openai.error.OpenAIError as e:
        # Handle OpenAI API errors
        print(f"An error occurred with the OpenAI API: {e}")

#-------------------------------------- Task 7: simulate negotiation. ---------------------------------------


def simulate_negotiation(customer_input, scenario):
    """
    Simulate a negotiation between a customer and a salesperson using the GPT-3.5 Turbo model.

    Args:
        customer_input (str): The input from the customer initiating the negotiation.
        scenario (str): A description of the negotiation scenario or context.
        conversation (list, optional): A list of conversation messages, including system, user, and assistant messages.
                                    Defaults to an empty list.

    Returns:
        str: The response generated by the GPT-3.5 Turbo model.

    Example:
        customer_input = "Can you provide a discount on this product?"
        scenario = "Customer requests a discount on a product."
        response = simulate_negotiation(customer_input, scenario)
        print(response)

    Note:
        - The function uses the GPT-3.5 Turbo model to generate a response based on the provided conversation context.
        - You can customize the 'conversation' list to include more context if needed.
    """
    
    # Define personas for the negotiation
    #salesperson_persona = "You are an enthusiastic salesperson trying to convince the customer of the product's value."    

    # Generate a response from the GPT-3.5 Turbo engine
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
                    messages=[
                {"role": "system", "content": scenario},
                {"role": "user", "content": customer_input},
            ],
        max_tokens=200  # Adjust this based on your requirements
    )

    return response['choices'][0]['message']['content']


#-------------------------------------- Task 8: fine-tuning on negotiation scenarios. ---------------------------------------

def fine_tuned_simulation(user_message):
    """
    Provides negotiation simulator using the OpenAI GPT-3.5 Turbo fine-tuned model.

    The function allows users to engage in a simulated negotiation with the AI model.
    Users can type messages, and the AI model responds with insights and suggestions.

    Args:
        user_message (str): The message from the user.

    Returns:
        str: The AI's response message.
    """
    try:
        # Send user's message to the AI model
        response = openai.ChatCompletion.create(
            model="ft:gpt-3.5-turbo-0613:chattech-corp::81PUD6U3"
            
,
            messages=[
                {"role": "system", "content": "You are a salesperson negotiating a deal with a customer."},
                {"role": "user", "content": user_message},
            ]

        )


        ai_message = response['choices'][0]['message']['content']
        return str(ai_message)

    except openai.error.OpenAIError as e:
        # Handle OpenAI API errors
        return f"AI: An error occurred with the OpenAI API: {e}"

import os
import openai

def load_jsonl_file(file_path):
    """
    Load a JSONL file for fine-tuning and return the OpenAI response.

    Args:
        file_path (str): The path to the JSONL file to be uploaded for fine-tuning.

    Returns:
        dict: The response from the OpenAI API, including information about the uploaded file.

    Example:
        file_path = "your_file.jsonl"
        response = load_jsonl_file(file_path)
        print(response)

    Note:
        - This function uploads a JSONL file to OpenAI for fine-tuning and stores the response.
        - It also saves information about the uploaded file in a result file.
    """
    try:
        # Create a file for fine-tuning
        response = openai.File.create(
            file=open(file_path, "rb"),
            purpose='fine-tune'
        )

        result_dir = os.path.join(os.curdir, "result_files")

        generate_result_file(result_dir, "08_Uploaded_file_info", response.__str__())

        return response
    
    except openai.error.OpenAIError as e:
        # Handle OpenAI API errors
        print(f"An error occurred with the OpenAI API: {e}")
        return None


def fine_tune(file_id, used_model="gpt-3.5-turbo"):
    """
    Start fine-tuning using a specified training file and model.

    Args:
        file_id (str): The ID of the training file to be used for fine-tuning.
        used_model (str, optional): The GPT model to use for fine-tuning. Defaults to "gpt-3.5-turbo".

    Returns:
        dict: The response from the OpenAI API, including information about the fine-tuning job.

    Example:
        file_id = "your_file_id"
        response = fine_tune(file_id)
        print(response)

    Note:
        - This function initiates the fine-tuning process on OpenAI using a specified training file and model.
        - It also saves information about the fine-tuning job in a result file.
    """
    try:
        response = openai.FineTuningJob.create(training_file=file_id, model=used_model)
        result_dir = os.path.join(os.curdir, "result_files")

        generate_result_file(result_dir, "08_tf_model_info", response.__str__())

        return response
    
    except openai.error.OpenAIError as e:
        # Handle OpenAI API errors
        print(f"An error occurred with the OpenAI API: {e}")
        return None




#uploaded_file_id = load_jsonl_file("scenarios.jsonl")
#tuned_model = fine_tune("file-tkZAKjkRxMtG0nfn5sjy4KWz")

# Retrieve the state of a fine-tune
#openai.FineTuningJob.retrieve("file-tkZAKjkRxMtG0nfn5sjy4KWz")

# List all of your fine-tune jobs
#print(openai.FineTuningJob.list())
#print(fine_tuned_simulation('who are u?'))

# ----------------------------------------------additional used functions --------------------------------------------

# Define a function to handle file uploads and return the saved file path
def handle_file_upload(file, upload_dir, prefix, extention ='txt'):
    """
    Handle file upload and save it to the specified directory with a unique filename.
    
    Args:
        file: The uploaded file.
        upload_dir (str): The directory where the file should be saved.
        prefix (str): The prefix to be used in the filename.

    Returns:
        str: The path to the saved file or None if upload failed.
    """
    if not file:
        return None
    timestamp = datetime.now().strftime("%Y_%m_%d_%H%M%S")
    filename = f"{prefix}_{timestamp}.{extention}"
    file_path = os.path.join(upload_dir, filename)
    file.save(file_path)

    
    return file_path

# Define a function to generate result files
def generate_result_file(result_dir, prefix, content):
    """
    Generate a result file with a unique filename and save it to the specified directory.

    Args:
        result_dir (str): The directory where the result file should be saved.
        prefix (str): The prefix to be used in the filename.
        content (str): The content to be written to the result file.

    Returns:
        str: The filename of the generated result file.
    """
    if not os.path.exists(result_dir):
        os.makedirs(result_dir)
    timestamp = datetime.now().strftime("%Y_%m_%d_%H%M%S")
    result_filename = f"{prefix}_{timestamp}.txt"
    result_file_path = os.path.join(result_dir, result_filename)
    with open(result_file_path, "w") as result_file:
        result_file.write(content)
    return result_filename


